{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc']\n",
      "857 documents\n",
      "2 categories\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['std', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__max_iter': (10, 50, 80, 150),\n",
      " 'clf__penalty': ('l2', 'elasticnet')}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-51d748b9788f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# grid_search.fit(data.data, data.target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', SGDClassifier()),\n",
    "# ])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    # grid_search.fit(data.data, data.target)\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8129\n",
      "          1       0.95      0.78      0.86       819\n",
      "\n",
      "avg / total       0.98      0.98      0.97      8948\n",
      "\n",
      "[[8097   32]\n",
      " [ 182  637]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "parameters = {\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__max_iter': (10, 50, 80, 150),\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "pipeline = Pipeline([ ('std', StandardScaler()), ('clf', SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score, get_scorer\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "class Cascador(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model=None, cv=5, mem=True, policy='majority', \n",
    "                 random_state=42, optim=False, parameters=None, metric='accuracy', max_steps=3):\n",
    "        self.base = model\n",
    "        self.cv = cv\n",
    "        self.mem = mem\n",
    "        if self.mem:\n",
    "            self.tree = 'Will be fitted!'\n",
    "        else:\n",
    "            self.tree = None\n",
    "        self.rs = random_state\n",
    "        self.optim = optim\n",
    "        if self.optim:\n",
    "            self.parameters = parameters\n",
    "        else:\n",
    "            self.parameters = None\n",
    "        self.scoring = get_scorer(metric)\n",
    "        self.max_steps = max_steps\n",
    "        self.acc = []\n",
    "        self.models = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if not(isinstance(X, np.ndarray)):\n",
    "            X_skf_next = np.array(X)\n",
    "        else:\n",
    "            X_skf_next = X\n",
    "        if not(isinstance(y, np.ndarray)):\n",
    "            y_skf_next = np.array(y)\n",
    "        else:\n",
    "            y_skf_next = y\n",
    "        #if self.tree:\n",
    "        #    self.tree = BallTree(X, leaf_size=20)\n",
    "        skf = StratifiedKFold(n_splits=self.cv, random_state=self.rs, shuffle=False)\n",
    "        for i in xrange(self.max_steps):\n",
    "            print('STEP %d' %i)\n",
    "            X_skf = X_skf_next[1:]\n",
    "            y_skf = y_skf_next[1:]\n",
    "            print(X_skf.shape, y_skf.shape)\n",
    "            #print(y_skf)\n",
    "            print(type(y_skf))\n",
    "            print(y_skf.shape)\n",
    "            #print(X_skf)\n",
    "            print('Y~'*50)\n",
    "            print(y_skf)\n",
    "            print(set(y_skf))\n",
    "            split = skf.split(X_skf, y_skf)\n",
    "            #print(split.next())\n",
    "            X_skf_next = None\n",
    "            y_skf_next = None\n",
    "            for train_index, test_index in split:\n",
    "                print(train_index.shape, test_index.shape)\n",
    "                X_train, X_test = X_skf[train_index], X_skf[test_index]\n",
    "                y_train, y_test = y_skf[train_index], y_skf[test_index]\n",
    "                cur_mod = deepcopy(self.base)\n",
    "                if self.optim:\n",
    "                    grid_search = GridSearchCV(cur_mod, self.parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "                    grid_search.fit(X_train, y_train)\n",
    "                    cur_mod = grid_search.best_estimator_\n",
    "                else:\n",
    "                    cur_mod.fit(X_train, y_train)\n",
    "                cur_pred = cur_mod.predict(X_test)\n",
    "                self.acc.append(accuracy_score(y_test, cur_pred))\n",
    "                self.models.append(cur_mod)\n",
    "                if X_skf is None:\n",
    "                    X_skf_next = X_test[cur_pred != y_test]\n",
    "                    y_skf_next = y_test[cur_pred != y_test]\n",
    "                else:\n",
    "                    X_skf_next = np.hstack((X_skf_next, X_test[cur_pred != y_test]))\n",
    "                    y_skf_next = np.hstack((y_skf_next, y_test[cur_pred != y_test]))\n",
    "                print(X_skf_next.shape, y_skf_next.shape)\n",
    "        self.acc = [100*acc/float(sum(self.acc)) for acc in self.acc]\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if not(isinstance(X, np.ndarray)):\n",
    "            X = np.array(X)\n",
    "        predictions = np.empty((X.shape[0], len(self.models)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[:, i] = model.predict(X)\n",
    "        final_pred = []\n",
    "        for sample in xrange(X.shape[0]):\n",
    "            votes = []\n",
    "            for i, mod_vote in predictions[sample,:]:\n",
    "                votes.extend([predictions[sample, i] for j in xrange(int(self.acc[i]))])\n",
    "            final_pred = most_common(votes)\n",
    "        return final_pred\n",
    "    \n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "            \n",
    "            \n",
    "                \n",
    "cs = Cascador(pipeline, cv=3, mem=True, policy='majority', \n",
    "                 random_state=42, optim=False, parameters=None, metric='accuracy', max_steps=2)           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8950\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  48 | elapsed:    1.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "201\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "55\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "36\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "24\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "def make_batch(model, X, y, cv=6, rs=42, optim=False, parameters=None, scoring=accuracy_score):\n",
    "    if not(isinstance(X, np.ndarray)):\n",
    "        X= np.array(X)\n",
    "    else:\n",
    "        X = X\n",
    "    if not(isinstance(y, np.ndarray)):\n",
    "        y = np.array(y)\n",
    "    else:\n",
    "        y = y\n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=rs, shuffle=False)\n",
    "    split = skf.split(X, y)\n",
    "    X_next = []\n",
    "    y_next = []\n",
    "    for train_index, test_index in split:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        cur_mod = deepcopy(model)\n",
    "        if optim:\n",
    "            grid_search = GridSearchCV(cur_mod, parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            cur_mod = grid_search.best_estimator_\n",
    "        else:\n",
    "            cur_mod.fit(X_train, y_train)\n",
    "        cur_pred = cur_mod.predict(X_test)\n",
    "        X_next.extend(X_test[cur_pred != y_test])\n",
    "        y_next.extend(y_test[cur_pred != y_test])\n",
    "    cur_mod = deepcopy(model)\n",
    "    if optim:\n",
    "        grid_search = GridSearchCV(cur_mod, parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        cur_mod = grid_search.best_estimator_\n",
    "    else:\n",
    "        cur_mod.fit(X, y)\n",
    "    return cur_mod, X_next, y_next\n",
    "\n",
    "models = []\n",
    "X_next = deepcopy(X_train)\n",
    "y_next = deepcopy(y_train)\n",
    "trees = []\n",
    "\n",
    "while len(X_next)> 20:\n",
    "    trees.append(BallTree(X_next))\n",
    "    print(len(X_next))\n",
    "    mod, X_next, y_next = make_batch(pipeline, X_next, y_next, optim=True, parameters=parameters)\n",
    "    #print(len(X_next))\n",
    "    models.append(mod)\n",
    "    print(\"~\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974631202503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      8129\n",
      "          1       0.89      0.83      0.86       819\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8948\n",
      "\n",
      "[[8043   86]\n",
      " [ 141  678]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def predict_from_forest(sample, models, trees):\n",
    "    dist = []\n",
    "    ind = []\n",
    "    for i, tree in enumerate(trees):\n",
    "        dist.append(tree.query(sample.reshape(1,-1))[0][0][0])\n",
    "        #ind.append(tree.query(sample.reshape(1,-1))[1][0][0])\n",
    "    wanted_mod = np.argmin(dist)\n",
    "    order = np.argsort(dist)\n",
    "    votes = []\n",
    "    for i, or_ in enumerate(order):\n",
    "        votes.extend([models[or_].predict(sample.reshape(1,-1))[0] for ii in xrange(len(order)-i)])\n",
    "    #print(dist, ind)\n",
    "    #print(len(models), wanted_mod)\n",
    "    return most_common(votes)\n",
    "    #return models[wanted_mod].predict(sample.reshape(1,-1))[0]\n",
    "\n",
    "pred2 = []\n",
    "for x in X_test:\n",
    "    #print(x.shape)\n",
    "    pred2.append(predict_from_forest(x, models, trees))\n",
    "    #return models\n",
    "print(accuracy_score(y_test, pred2))\n",
    "print(classification_report(y_test, pred2))\n",
    "print(confusion_matrix(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "0.979213232007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      8129\n",
      "          1       0.91      0.86      0.88       819\n",
      "\n",
      "avg / total       0.98      0.98      0.98      8948\n",
      "\n",
      "[[8061   68]\n",
      " [ 118  701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__max_iter': (10, 50, 80, 150),\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908471166741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95      8129\n",
      "          1       0.00      0.00      0.00       819\n",
      "\n",
      "avg / total       0.83      0.91      0.86      8948\n",
      "\n",
      "[[8129    0]\n",
      " [ 819    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "#pipeline2 = Pipeline([('clf', SVC())])\n",
    "#ac = AdaBoostClassifier(SVC(), algorithm='SAMME')\n",
    "#ac.fit(X_train, y_train)\n",
    "pred3 = ac.predict(X_test)\n",
    "print(accuracy_score(y_test, pred3))\n",
    "print(classification_report(y_test, pred3))\n",
    "print(confusion_matrix(y_test, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "def similarity_samples(sample, X):\n",
    "    from fuzzywuzzy import process\n",
    "    process.extractOne(sample, X)\n",
    "\n",
    "closest = np.argmin(euclidean_distances(X[0].reshape(1,-1), X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90891819401\n"
     ]
    }
   ],
   "source": [
    "def predict(models, X_test, policy='voting'):\n",
    "    if policy == 'voting':\n",
    "        pred = []\n",
    "        for x in X_test:\n",
    "            votes = []\n",
    "            for model in models:\n",
    "                votes.append(model.predict([x])[0])\n",
    "            pred.append(most_common(votes))\n",
    "    return pred\n",
    "pred2 = predict(models, X_test)\n",
    "print(accuracy_score(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a7205920bf59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcur_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y)\n",
    "grid_search.fit(X_train, y_train)\n",
    "cur_mod = grid_search.best_estimator_\n",
    "pred = cur_mod.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-17fc877ca278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n",
    "split = skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0\n",
      "(641,) (641,)\n",
      "<type 'numpy.ndarray'>\n",
      "(641,)\n",
      "Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~\n",
      "[0 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0\n",
      " 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 1 1 1 1 0 1 1 0 0 0 0 0]\n",
      "set([0, 1])\n",
      "(426,) (215,)\n",
      "(14,) (14,)\n",
      "(428,) (213,)\n",
      "(37,) (37,)\n",
      "(428,) (213,)\n",
      "(53,) (53,)\n",
      "STEP 1\n",
      "(52,) (52,)\n",
      "<type 'numpy.ndarray'>\n",
      "(52,)\n",
      "Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~Y~\n",
      "[1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0]\n",
      "set([0, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-85e55480bac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ac28ab17d1dc>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mX_skf_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0my_skf_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_skf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_skf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    330\u001b[0m                                                              n_samples))\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    587\u001b[0m             raise ValueError(\n\u001b[0;32m    588\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m--> 589\u001b[1;33m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y)\n",
    "cs.fit(X_train, y_train)\n",
    "cs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open('/home/bogas/workspace/DATA/HTRU2/HTRU_2.csv', 'r') as f:\n",
    "    df = pd.read_csv(f, header=None)\n",
    "y = df[8]\n",
    "del df[8]\n",
    "X = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17898, 8) (17898,)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target\n",
    "X = data.data\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7fb1c07b48b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7fb1c07b48b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    400         \n    401         if self.poller is not None:\n    402             self.poller.start()\n    403         self.kernel.start()\n    404         try:\n--> 405             ioloop.IOLoop.instance().start()\n    406         except KeyboardInterrupt:\n    407             pass\n    408 \n    409 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['4FC3A118EDB349AFA22A73B0C1416B74']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['4FC3A118EDB349AFA22A73B0C1416B74'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.For object>, <_ast.Expr object>], cell_name='<ipython-input-28-476ca1e50d1e>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>\n        self.user_global_ns = {'BallTree': <type 'sklearn.neighbors.ball_tree.BallTree'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'Cascador': <class '__main__.Cascador'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'from __future__ import print_function\\n\\nfrom ...%r\" % (param_name, best_parameters[param_name]))', u\"import numpy as np\\nfrom sklearn.base import B...accuracy', max_steps=2)           \\n            \", u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u'def similarity_samples(sample, X):\\n    from f...mport process\\n    process.extractOne(sample, X)', u\"def predict(models, X_test, policy='voting'):\\...s, X_test)\\nprint(accuracy_score(y_test, pred2))\", u'from sklearn.model_selection import train_test...ict(X_test)\\nprint(accuracy_score(y_test, pred))', u'skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\\nsplit = skf.split(X, y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'y = data.target\\nX = data.data\\nX = np.array(X)\\ny = np.array(y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u\"import pandas as pd\\nwith open('/home/bogas/workspace/DATA/HTRU2/HTRU_2.csv', 'r') as f:\\n    pd\", u\"import pandas as pd\\nwith open('/home/bogas/wo..._2.csv', 'r') as f:\\n    df = pd.read_csv(f)\\ndf\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r') as f:\\n    df = pd.read_csv(f, header=False)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...'r') as f:\\n    df = pd.read_csv(f, header=None)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...n    df = pd.read_csv(f, header=None)\\ndf.head()\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r=None)\\ny = df[8]\\ndel df[8]\\nX = df.to_dense()\", u'X', u'X.to_xarray', ...], 'Out': {13:          140.5625  55.68378214  -0.234571412  -0...97527     1.429475  0  \n\n[17897 rows x 9 columns], 16:             0          1         2         3    ...171909  0  \n3   53.593661  0  \n4  252.567306  0  , 18:                 0          1         2         3...-1.597527    1.429475  \n\n[17898 rows x 8 columns], 19: <bound method DataFrame.to_xarray of            ...1.597527    1.429475  \n\n[17898 rows x 8 columns]>, 21: array([[ 140.5625    ,   55.68378214,   -0.23457...71256228,\n          -1.59752658,    1.42947536]]), 22: (17898, 8)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n        self.user_ns = {'BallTree': <type 'sklearn.neighbors.ball_tree.BallTree'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'Cascador': <class '__main__.Cascador'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'from __future__ import print_function\\n\\nfrom ...%r\" % (param_name, best_parameters[param_name]))', u\"import numpy as np\\nfrom sklearn.base import B...accuracy', max_steps=2)           \\n            \", u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u'def similarity_samples(sample, X):\\n    from f...mport process\\n    process.extractOne(sample, X)', u\"def predict(models, X_test, policy='voting'):\\...s, X_test)\\nprint(accuracy_score(y_test, pred2))\", u'from sklearn.model_selection import train_test...ict(X_test)\\nprint(accuracy_score(y_test, pred))', u'skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\\nsplit = skf.split(X, y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'y = data.target\\nX = data.data\\nX = np.array(X)\\ny = np.array(y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u\"import pandas as pd\\nwith open('/home/bogas/workspace/DATA/HTRU2/HTRU_2.csv', 'r') as f:\\n    pd\", u\"import pandas as pd\\nwith open('/home/bogas/wo..._2.csv', 'r') as f:\\n    df = pd.read_csv(f)\\ndf\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r') as f:\\n    df = pd.read_csv(f, header=False)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...'r') as f:\\n    df = pd.read_csv(f, header=None)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...n    df = pd.read_csv(f, header=None)\\ndf.head()\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r=None)\\ny = df[8]\\ndel df[8]\\nX = df.to_dense()\", u'X', u'X.to_xarray', ...], 'Out': {13:          140.5625  55.68378214  -0.234571412  -0...97527     1.429475  0  \n\n[17897 rows x 9 columns], 16:             0          1         2         3    ...171909  0  \n3   53.593661  0  \n4  252.567306  0  , 18:                 0          1         2         3...-1.597527    1.429475  \n\n[17898 rows x 8 columns], 19: <bound method DataFrame.to_xarray of            ...1.597527    1.429475  \n\n[17898 rows x 8 columns]>, 21: array([[ 140.5625    ,   55.68378214,   -0.23457...71256228,\n          -1.59752658,    1.42947536]]), 22: (17898, 8)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/bogas/workspace/GIT/Cascada/<ipython-input-28-476ca1e50d1e> in <module>()\n      1 skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=False)\n      2 for train_index, test_index in skf.split(X, y):\n      3     X_train, X_test = X[train_index], X[test_index]\n      4     y_train, y_test = y[train_index], y[test_index]\n----> 5 grid_search.fit(X_train, y_train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Tue Feb 13 00:00:49 2018\nPID: 5000                                     Python 2.7.6: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, {'score': <function _passthrough_scorer>}, array([2977, 2981, 2982, ..., 8947, 8948, 8949]), array([   0,    1,    2, ..., 2984, 2985, 2986]), 1, {'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, {'score': <function _passthrough_scorer>}, array([2977, 2981, 2982, ..., 8947, 8948, 8949]), array([   0,    1,    2, ..., 2984, 2985, 2986]), 1, {'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([2977, 2981, 2982, ..., 8947, 8948, 8949]), test=array([   0,    1,    2, ..., 2984, 2985, 2986]), verbose=1, parameters={'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=True, tol=None, verbose=0, warm_start=False))])>\n        X_train = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y_train = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=True, tol=None, verbose=0, warm_start=False))])>\n        X = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7fb17f6077d0>), *args=(CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), fixed_vocab=False)\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n    790         for doc in raw_documents:\n    791             feature_counter = {}\n--> 792             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function <lambda>>\n        doc = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n    793                 try:\n    794                     feature_idx = vocabulary[feature]\n    795                     if feature_idx not in feature_counter:\n    796                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in <lambda>(doc=array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139]))\n    261         elif self.analyzer == 'word':\n    262             stop_words = self.get_stop_words()\n    263             tokenize = self.build_tokenizer()\n    264 \n    265             return lambda doc: self._word_ngrams(\n--> 266                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    270                              self.analyzer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in <lambda>(x=array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139]))\n    227         else:\n    228             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    229                              self.strip_accents)\n    230 \n    231         if self.lowercase:\n--> 232             return lambda x: strip_accents(x.lower())\n        x = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n        x.lower = undefined\n    233         else:\n    234             return strip_accents\n    235 \n    236     def build_tokenizer(self):\n\nAttributeError: 'numpy.ndarray' object has no attribute 'lower'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-476ca1e50d1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7fb1c07b48b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7fb1c07b48b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    400         \n    401         if self.poller is not None:\n    402             self.poller.start()\n    403         self.kernel.start()\n    404         try:\n--> 405             ioloop.IOLoop.instance().start()\n    406         except KeyboardInterrupt:\n    407             pass\n    408 \n    409 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['4FC3A118EDB349AFA22A73B0C1416B74']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['4FC3A118EDB349AFA22A73B0C1416B74'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'skf = StratifiedKFold(n_splits=2, random_state=4..., y[test_index]\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-02-13T00:00:49.117907', 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'session': '4FC3A118EDB349AFA22A73B0C1416B74', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1AC0E6EDC71C41D5A0A739F92346209C', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'skf = StratifiedKFold(n_splits=2, random_state...y[test_index]\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.For object>, <_ast.Expr object>], cell_name='<ipython-input-28-476ca1e50d1e>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb1528e19b0, file \"<ipython-input-28-476ca1e50d1e>\", line 5>\n        self.user_global_ns = {'BallTree': <type 'sklearn.neighbors.ball_tree.BallTree'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'Cascador': <class '__main__.Cascador'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'from __future__ import print_function\\n\\nfrom ...%r\" % (param_name, best_parameters[param_name]))', u\"import numpy as np\\nfrom sklearn.base import B...accuracy', max_steps=2)           \\n            \", u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u'def similarity_samples(sample, X):\\n    from f...mport process\\n    process.extractOne(sample, X)', u\"def predict(models, X_test, policy='voting'):\\...s, X_test)\\nprint(accuracy_score(y_test, pred2))\", u'from sklearn.model_selection import train_test...ict(X_test)\\nprint(accuracy_score(y_test, pred))', u'skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\\nsplit = skf.split(X, y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'y = data.target\\nX = data.data\\nX = np.array(X)\\ny = np.array(y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u\"import pandas as pd\\nwith open('/home/bogas/workspace/DATA/HTRU2/HTRU_2.csv', 'r') as f:\\n    pd\", u\"import pandas as pd\\nwith open('/home/bogas/wo..._2.csv', 'r') as f:\\n    df = pd.read_csv(f)\\ndf\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r') as f:\\n    df = pd.read_csv(f, header=False)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...'r') as f:\\n    df = pd.read_csv(f, header=None)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...n    df = pd.read_csv(f, header=None)\\ndf.head()\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r=None)\\ny = df[8]\\ndel df[8]\\nX = df.to_dense()\", u'X', u'X.to_xarray', ...], 'Out': {13:          140.5625  55.68378214  -0.234571412  -0...97527     1.429475  0  \n\n[17897 rows x 9 columns], 16:             0          1         2         3    ...171909  0  \n3   53.593661  0  \n4  252.567306  0  , 18:                 0          1         2         3...-1.597527    1.429475  \n\n[17898 rows x 8 columns], 19: <bound method DataFrame.to_xarray of            ...1.597527    1.429475  \n\n[17898 rows x 8 columns]>, 21: array([[ 140.5625    ,   55.68378214,   -0.23457...71256228,\n          -1.59752658,    1.42947536]]), 22: (17898, 8)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n        self.user_ns = {'BallTree': <type 'sklearn.neighbors.ball_tree.BallTree'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'Cascador': <class '__main__.Cascador'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'from __future__ import print_function\\n\\nfrom ...%r\" % (param_name, best_parameters[param_name]))', u\"import numpy as np\\nfrom sklearn.base import B...accuracy', max_steps=2)           \\n            \", u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u'def similarity_samples(sample, X):\\n    from f...mport process\\n    process.extractOne(sample, X)', u\"def predict(models, X_test, policy='voting'):\\...s, X_test)\\nprint(accuracy_score(y_test, pred2))\", u'from sklearn.model_selection import train_test...ict(X_test)\\nprint(accuracy_score(y_test, pred))', u'skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\\nsplit = skf.split(X, y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'y = data.target\\nX = data.data\\nX = np.array(X)\\ny = np.array(y)', u'from sklearn.model_selection import train_test...y)\\ncs.fit(X_train, y_train)\\ncs.predict(X_test)', u'def make_batch(model, X, y, cv=6, rs=42, optim...ext))\\n    models.append(mod)\\n    print(\"~\"*50)', u\"import pandas as pd\\nwith open('/home/bogas/workspace/DATA/HTRU2/HTRU_2.csv', 'r') as f:\\n    pd\", u\"import pandas as pd\\nwith open('/home/bogas/wo..._2.csv', 'r') as f:\\n    df = pd.read_csv(f)\\ndf\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r') as f:\\n    df = pd.read_csv(f, header=False)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...'r') as f:\\n    df = pd.read_csv(f, header=None)\", u\"import pandas as pd\\nwith open('/home/bogas/wo...n    df = pd.read_csv(f, header=None)\\ndf.head()\", u\"import pandas as pd\\nwith open('/home/bogas/wo...r=None)\\ny = df[8]\\ndel df[8]\\nX = df.to_dense()\", u'X', u'X.to_xarray', ...], 'Out': {13:          140.5625  55.68378214  -0.234571412  -0...97527     1.429475  0  \n\n[17897 rows x 9 columns], 16:             0          1         2         3    ...171909  0  \n3   53.593661  0  \n4  252.567306  0  , 18:                 0          1         2         3...-1.597527    1.429475  \n\n[17898 rows x 8 columns], 19: <bound method DataFrame.to_xarray of            ...1.597527    1.429475  \n\n[17898 rows x 8 columns]>, 21: array([[ 140.5625    ,   55.68378214,   -0.23457...71256228,\n          -1.59752658,    1.42947536]]), 22: (17898, 8)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/bogas/workspace/GIT/Cascada/<ipython-input-28-476ca1e50d1e> in <module>()\n      1 skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=False)\n      2 for train_index, test_index in skf.split(X, y):\n      3     X_train, X_test = X[train_index], X[test_index]\n      4     y_train, y_test = y[train_index], y[test_index]\n----> 5 grid_search.fit(X_train, y_train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Tue Feb 13 00:00:49 2018\nPID: 5000                                     Python 2.7.6: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, {'score': <function _passthrough_scorer>}, array([2977, 2981, 2982, ..., 8947, 8948, 8949]), array([   0,    1,    2, ..., 2984, 2985, 2986]), 1, {'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, {'score': <function _passthrough_scorer>}, array([2977, 2981, 2982, ..., 8947, 8948, 8949]), array([   0,    1,    2, ..., 2984, 2985, 2986]), 1, {'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  1.40562500e+02,   5.56837821e+01,  -2....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=0       0\n1       0\n2       0\n3       0\n4       ...  0\n9322    0\nName: 8, Length: 8950, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([2977, 2981, 2982, ..., 8947, 8948, 8949]), test=array([   0,    1,    2, ..., 2984, 2985, 2986]), verbose=1, parameters={'clf__alpha': 1e-05, 'clf__penalty': 'l2', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=True, tol=None, verbose=0, warm_start=False))])>\n        X_train = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y_train = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=True, tol=None, verbose=0, warm_start=False))])>\n        X = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7fb17f6077d0>), *args=(CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]])\n        y = 2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), y=2977    1\n2981    1\n2982    1\n2987    1\n2988    ...  0\n9322    0\nName: 8, Length: 5966, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer=u'word', binary=False, ...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=array([[  8.03515625e+01,   3.97448090e+01,   1....915249e+01,   7.58592123e+00,   8.34460142e+01]]), fixed_vocab=False)\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n    790         for doc in raw_documents:\n    791             feature_counter = {}\n--> 792             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function <lambda>>\n        doc = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n    793                 try:\n    794                     feature_idx = vocabulary[feature]\n    795                     if feature_idx not in feature_counter:\n    796                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in <lambda>(doc=array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139]))\n    261         elif self.analyzer == 'word':\n    262             stop_words = self.get_stop_words()\n    263             tokenize = self.build_tokenizer()\n    264 \n    265             return lambda doc: self._word_ngrams(\n--> 266                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    270                              self.analyzer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py in <lambda>(x=array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139]))\n    227         else:\n    228             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    229                              self.strip_accents)\n    230 \n    231         if self.lowercase:\n--> 232             return lambda x: strip_accents(x.lower())\n        x = array([ 80.3515625 ,  39.74480899,   1.16691178,...86957,  26.66195868,   6.62937054,  44.88527139])\n        x.lower = undefined\n    233         else:\n    234             return strip_accents\n    235 \n    236     def build_tokenizer(self):\n\nAttributeError: 'numpy.ndarray' object has no attribute 'lower'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=False)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1 - accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pred != y_test)[0]\n",
    "#print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
