{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example use of the hyperopt to see the sensitivy of an algorith with respect ot their hyperparameters\n",
    "Here the use-case is a RandomForest algo and see the importance of different hyperaparameters based on the accuracy on the train and test set.\n",
    "Simple train/test split has been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc']\n",
      "857 documents\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "#############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__max_iter': (10, 50, 80, 150),\n",
    "}\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "#     print(\"Performing grid search...\")\n",
    "#     print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "#     print(\"parameters:\")\n",
    "#     pprint(parameters)\n",
    "#     t0 = time()\n",
    "#     # grid_search.fit(data.data, data.target)\n",
    "#     grid_search.fit(X, y)\n",
    "#     print(\"done in %0.3fs\" % (time() - t0))\n",
    "#     print()\n",
    "\n",
    "#     print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "#     print(\"Best parameters set:\")\n",
    "#     best_parameters = grid_search.best_estimator_.get_params()\n",
    "#     for param_name in sorted(parameters.keys()):\n",
    "#         print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    6.2s finished\n",
      "/home/kostas/.local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "# X_valid, X_test, y_valid, y_test= train_test_split(X_test, y_test, \n",
    "#                                                    random_state=42, test_size=0.5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "cur_mod = grid_search.best_estimator_\n",
    "pred = cur_mod.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15443 15443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pip = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())])\n",
    "\n",
    "tr = pip.fit_transform(X_train, y_train)\n",
    "mi = mutual_info_classif(tr, y_train)\n",
    "print(len(mi),tr.shape[1])\n",
    "mi = mi/sum(mi)\n",
    "#tr_valid = pip.transform(X_valid)\n",
    "tr_test = pip.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8643410852713178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.utils import check_X_y, check_random_state, check_array\n",
    "from sklearn.metrics import get_scorer\n",
    "from sklearn.utils.validation import column_or_1d, check_is_fitted\n",
    "from sklearn.multiclass import check_classification_targets\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class Liquid_Voter2(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Liquid Voter delegation mechanism. It builds a standard random forest but\n",
    "    votes according to the liquid voting mechanism of action. Currently, the competence\n",
    "    is expressed through the accuracy of the trees based on a validation split on the \n",
    "    train set. The alpha and cap parameters essentially control a) how much better does\n",
    "    one model to be with regards to another so as to become it's delegate and b) the maximum\n",
    "    capacity of votes one delegate can carry.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 ensemble=RandomForestClassifier(), \n",
    "                 n_estimators=100,  \n",
    "                 random_state=42,\n",
    "                min_samples_leaf=2,\n",
    "                 #competence = 'valid_acc',\n",
    "                 valid_size = 0.1,\n",
    "                 alpha = 0.2,\n",
    "                 cap = 0.2,\n",
    "                 metric='accuracy'):  \n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.ensemble = ensemble.set_params(**{'random_state':self.random_state,\n",
    "                                            'n_estimators':self.n_estimators,\n",
    "                                              'min_samples_leaf':self.min_samples_leaf})\n",
    "        self.alpha = alpha\n",
    "        self.cap = cap\n",
    "        self.scoring = get_scorer(metric)\n",
    "        #self.competence = competence\n",
    "        self.valid_size = valid_size\n",
    "        self.delegation_map = {}\n",
    "        self.competence = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self._fit(X, y)\n",
    "    \n",
    "    def _validate_y(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def _fit(self,X,y):\n",
    "        X, y = check_X_y(\n",
    "            X, y, ['csr', 'csc'], dtype=None, force_all_finite=False,\n",
    "            multi_output=True)\n",
    "        y = self._validate_y(y)\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        self.ensemble.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _validate_y(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class for X.\n",
    "        The predicted class of an input sample is computed as the class with\n",
    "        the highest mean predicted probability. If base estimators do not\n",
    "        implement a ``predict_proba`` method, then it resorts to voting.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrices are accepted only if\n",
    "            they are supported by the base estimator.\n",
    "        Returns\n",
    "        -------\n",
    "        y : array of shape = [n_samples]\n",
    "            The predicted classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.predict_delegate_(X)\n",
    "    \n",
    "    def predict_delegate_(self, X):\n",
    "        import collections\n",
    "        import operator\n",
    "        final_pred = []\n",
    "        for sample in xrange(X.shape[0]):\n",
    "            # Competence\n",
    "            self.competence = []\n",
    "            for est in self.ensemble.estimators_:\n",
    "                proba = est.predict_proba(X[sample,:].reshape(1, -1))[0][0]\n",
    "                #print(proba)\n",
    "                comp = abs(proba-0.5)*2\n",
    "                self.competence.append(comp)\n",
    "            #print(self.competence)\n",
    "            # Delegation\n",
    "            approves = {}\n",
    "            approved_by = {}\n",
    "            approved_by_length = {}\n",
    "            for i, sc_i in enumerate(self.competence):\n",
    "                k = np.copy(self.competence)\n",
    "                approves[i] = np.where(k - sc_i - self.alpha>0)[0].tolist()\n",
    "                approved_by[i] = np.where(k - sc_i + self.alpha<0)[0].tolist()\n",
    "                approved_by_length[i] = len(approved_by[i])\n",
    "\n",
    "            sorted_approved = sorted(approved_by_length.items(), key=operator.itemgetter(1))[::-1]\n",
    "            cap = int(self.n_estimators*self.cap)\n",
    "            cap_per_est = {}\n",
    "            for i in xrange(self.n_estimators):\n",
    "                cap_per_est[i] = cap\n",
    "            poss_nodes = set([i for i in xrange(self.n_estimators)])\n",
    "            #print(sorted_approved)\n",
    "            for est_id, _ in sorted_approved:\n",
    "                to_deleg = []\n",
    "                poss_deleg = list(poss_nodes.intersection(approved_by[est_id]))\n",
    "                if len(poss_deleg) <= cap_per_est[est_id] - 1:\n",
    "                    to_deleg = poss_deleg\n",
    "                else:\n",
    "                    to_deleg = np.random.choice(poss_deleg, cap_per_est[est_id] - 1).tolist()\n",
    "                to_deleg = to_deleg + [est_id]\n",
    "                cap_per_est[est_id] -= len(to_deleg)\n",
    "                poss_nodes = poss_nodes.difference(to_deleg)\n",
    "                self.delegation_map[est_id] = to_deleg\n",
    "                if len(poss_nodes) == 0:\n",
    "                    break\n",
    "            \n",
    "            # Prediction\n",
    "            sample_pred = []\n",
    "            for est_id, delegates in self.delegation_map.items():\n",
    "                n_votes = len(delegates)\n",
    "                est_predict = self.ensemble.estimators_[est_id].predict(X[sample,:].reshape(1, -1))[0]\n",
    "                sample_pred.extend([est_predict for i in xrange(n_votes)])\n",
    "            final_pred.append(collections.Counter(sample_pred).most_common()[0][0])\n",
    "        return np.array(final_pred)  \n",
    "\n",
    "lv = Liquid_Voter2(alpha=2, cap=0.1, n_estimators=100, min_samples_leaf=2)\n",
    "lv.fit(tr,y_train)\n",
    "pred = lv.predict(tr_test[:])\n",
    "print(accuracy_score(y_test[:], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.arange(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:27:43,162 INFO Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt\n",
      "2019-06-20 16:27:43,179 INFO Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt\n",
      "2019-06-20 16:27:43,286 INFO tpe_transform took 0.001015 seconds\n",
      "2019-06-20 16:27:43,288 INFO TPE using 0 trials\n",
      "2019-06-20 16:28:23,488 INFO tpe_transform took 0.001069 seconds\n",
      "2019-06-20 16:28:23,489 INFO TPE using 1/1 trials with best loss 0.158915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.993  -- Validation score: 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:29:03,100 INFO tpe_transform took 0.001079 seconds\n",
      "2019-06-20 16:29:03,101 INFO TPE using 2/2 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:29:42,995 INFO tpe_transform took 0.000788 seconds\n",
      "2019-06-20 16:29:42,996 INFO TPE using 3/3 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.995  -- Validation score: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:30:23,076 INFO tpe_transform took 0.001061 seconds\n",
      "2019-06-20 16:30:23,077 INFO TPE using 4/4 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:31:03,346 INFO tpe_transform took 0.001243 seconds\n",
      "2019-06-20 16:31:03,347 INFO TPE using 5/5 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.993  -- Validation score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:31:43,197 INFO tpe_transform took 0.001135 seconds\n",
      "2019-06-20 16:31:43,199 INFO TPE using 6/6 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:32:22,947 INFO tpe_transform took 0.001125 seconds\n",
      "2019-06-20 16:32:22,949 INFO TPE using 7/7 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:33:03,093 INFO tpe_transform took 0.001228 seconds\n",
      "2019-06-20 16:33:03,094 INFO TPE using 8/8 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:33:42,858 INFO tpe_transform took 0.000805 seconds\n",
      "2019-06-20 16:33:42,860 INFO TPE using 9/9 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:34:22,846 INFO tpe_transform took 0.001073 seconds\n",
      "2019-06-20 16:34:22,847 INFO TPE using 10/10 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:35:02,920 INFO tpe_transform took 0.001114 seconds\n",
      "2019-06-20 16:35:02,922 INFO TPE using 11/11 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.995  -- Validation score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:35:43,189 INFO tpe_transform took 0.000909 seconds\n",
      "2019-06-20 16:35:43,191 INFO TPE using 12/12 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:36:23,364 INFO tpe_transform took 0.000924 seconds\n",
      "2019-06-20 16:36:23,365 INFO TPE using 13/13 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:37:03,171 INFO tpe_transform took 0.000799 seconds\n",
      "2019-06-20 16:37:03,172 INFO TPE using 14/14 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:37:43,389 INFO tpe_transform took 0.001072 seconds\n",
      "2019-06-20 16:37:43,390 INFO TPE using 15/15 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.997  -- Validation score: 0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:38:23,764 INFO tpe_transform took 0.000812 seconds\n",
      "2019-06-20 16:38:23,765 INFO TPE using 16/16 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:39:03,804 INFO tpe_transform took 0.000806 seconds\n",
      "2019-06-20 16:39:03,806 INFO TPE using 17/17 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.993  -- Validation score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:39:44,113 INFO tpe_transform took 0.001106 seconds\n",
      "2019-06-20 16:39:44,114 INFO TPE using 18/18 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:40:24,502 INFO tpe_transform took 0.001180 seconds\n",
      "2019-06-20 16:40:24,504 INFO TPE using 19/19 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:41:04,709 INFO tpe_transform took 0.000831 seconds\n",
      "2019-06-20 16:41:04,710 INFO TPE using 20/20 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:41:44,913 INFO tpe_transform took 0.001191 seconds\n",
      "2019-06-20 16:41:44,915 INFO TPE using 21/21 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:42:25,045 INFO tpe_transform took 0.001174 seconds\n",
      "2019-06-20 16:42:25,046 INFO TPE using 22/22 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:43:04,799 INFO tpe_transform took 0.001046 seconds\n",
      "2019-06-20 16:43:04,800 INFO TPE using 23/23 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:43:44,736 INFO tpe_transform took 0.001119 seconds\n",
      "2019-06-20 16:43:44,737 INFO TPE using 24/24 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:44:24,440 INFO tpe_transform took 0.001108 seconds\n",
      "2019-06-20 16:44:24,442 INFO TPE using 25/25 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:45:04,349 INFO tpe_transform took 0.001149 seconds\n",
      "2019-06-20 16:45:04,350 INFO TPE using 26/26 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:45:44,495 INFO tpe_transform took 0.000800 seconds\n",
      "2019-06-20 16:45:44,496 INFO TPE using 27/27 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:46:24,653 INFO tpe_transform took 0.001137 seconds\n",
      "2019-06-20 16:46:24,655 INFO TPE using 28/28 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:47:04,407 INFO tpe_transform took 0.001201 seconds\n",
      "2019-06-20 16:47:04,408 INFO TPE using 29/29 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:47:44,517 INFO tpe_transform took 0.001144 seconds\n",
      "2019-06-20 16:47:44,518 INFO TPE using 30/30 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:48:24,484 INFO tpe_transform took 0.000809 seconds\n",
      "2019-06-20 16:48:24,485 INFO TPE using 31/31 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:49:04,339 INFO tpe_transform took 0.001121 seconds\n",
      "2019-06-20 16:49:04,340 INFO TPE using 32/32 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:49:43,985 INFO tpe_transform took 0.001002 seconds\n",
      "2019-06-20 16:49:43,986 INFO TPE using 33/33 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:50:23,999 INFO tpe_transform took 0.001205 seconds\n",
      "2019-06-20 16:50:24,001 INFO TPE using 34/34 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:51:04,273 INFO tpe_transform took 0.001157 seconds\n",
      "2019-06-20 16:51:04,275 INFO TPE using 35/35 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:51:44,450 INFO tpe_transform took 0.001123 seconds\n",
      "2019-06-20 16:51:44,452 INFO TPE using 36/36 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:52:24,721 INFO tpe_transform took 0.001078 seconds\n",
      "2019-06-20 16:52:24,723 INFO TPE using 37/37 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:53:04,842 INFO tpe_transform took 0.001071 seconds\n",
      "2019-06-20 16:53:04,844 INFO TPE using 38/38 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:53:44,796 INFO tpe_transform took 0.001081 seconds\n",
      "2019-06-20 16:53:44,797 INFO TPE using 39/39 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:54:24,705 INFO tpe_transform took 0.001131 seconds\n",
      "2019-06-20 16:54:24,707 INFO TPE using 40/40 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:55:04,610 INFO tpe_transform took 0.000812 seconds\n",
      "2019-06-20 16:55:04,611 INFO TPE using 41/41 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.993  -- Validation score: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:55:44,584 INFO tpe_transform took 0.001143 seconds\n",
      "2019-06-20 16:55:44,586 INFO TPE using 42/42 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:56:25,041 INFO tpe_transform took 0.000796 seconds\n",
      "2019-06-20 16:56:25,042 INFO TPE using 43/43 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:57:05,258 INFO tpe_transform took 0.001133 seconds\n",
      "2019-06-20 16:57:05,260 INFO TPE using 44/44 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:57:45,472 INFO tpe_transform took 0.001135 seconds\n",
      "2019-06-20 16:57:45,473 INFO TPE using 45/45 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:58:26,569 INFO tpe_transform took 0.001077 seconds\n",
      "2019-06-20 16:58:26,571 INFO TPE using 46/46 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:59:06,586 INFO tpe_transform took 0.001061 seconds\n",
      "2019-06-20 16:59:06,587 INFO TPE using 47/47 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 16:59:46,429 INFO tpe_transform took 0.000815 seconds\n",
      "2019-06-20 16:59:46,431 INFO TPE using 48/48 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:00:26,664 INFO tpe_transform took 0.000799 seconds\n",
      "2019-06-20 17:00:26,666 INFO TPE using 49/49 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:01:06,891 INFO tpe_transform took 0.001072 seconds\n",
      "2019-06-20 17:01:06,893 INFO TPE using 50/50 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:01:47,298 INFO tpe_transform took 0.000797 seconds\n",
      "2019-06-20 17:01:47,299 INFO TPE using 51/51 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:02:27,628 INFO tpe_transform took 0.001213 seconds\n",
      "2019-06-20 17:02:27,630 INFO TPE using 52/52 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:03:08,008 INFO tpe_transform took 0.000818 seconds\n",
      "2019-06-20 17:03:08,009 INFO TPE using 53/53 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:03:47,926 INFO tpe_transform took 0.000855 seconds\n",
      "2019-06-20 17:03:47,927 INFO TPE using 54/54 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:04:28,269 INFO tpe_transform took 0.001156 seconds\n",
      "2019-06-20 17:04:28,271 INFO TPE using 55/55 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:05:08,195 INFO tpe_transform took 0.000818 seconds\n",
      "2019-06-20 17:05:08,196 INFO TPE using 56/56 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:05:48,337 INFO tpe_transform took 0.001358 seconds\n",
      "2019-06-20 17:05:48,338 INFO TPE using 57/57 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:06:28,608 INFO tpe_transform took 0.000818 seconds\n",
      "2019-06-20 17:06:28,609 INFO TPE using 58/58 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:07:08,948 INFO tpe_transform took 0.000838 seconds\n",
      "2019-06-20 17:07:08,950 INFO TPE using 59/59 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:07:48,945 INFO tpe_transform took 0.000822 seconds\n",
      "2019-06-20 17:07:48,946 INFO TPE using 60/60 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:08:29,164 INFO tpe_transform took 0.001083 seconds\n",
      "2019-06-20 17:08:29,166 INFO TPE using 61/61 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:09:09,363 INFO tpe_transform took 0.001123 seconds\n",
      "2019-06-20 17:09:09,365 INFO TPE using 62/62 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:09:49,755 INFO tpe_transform took 0.000800 seconds\n",
      "2019-06-20 17:09:49,757 INFO TPE using 63/63 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:10:29,969 INFO tpe_transform took 0.001080 seconds\n",
      "2019-06-20 17:10:29,971 INFO TPE using 64/64 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:11:10,009 INFO tpe_transform took 0.000818 seconds\n",
      "2019-06-20 17:11:10,010 INFO TPE using 65/65 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:11:50,478 INFO tpe_transform took 0.001088 seconds\n",
      "2019-06-20 17:11:50,479 INFO TPE using 66/66 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:12:31,111 INFO tpe_transform took 0.000810 seconds\n",
      "2019-06-20 17:12:31,112 INFO TPE using 67/67 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:13:11,526 INFO tpe_transform took 0.001233 seconds\n",
      "2019-06-20 17:13:11,528 INFO TPE using 68/68 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:13:52,099 INFO tpe_transform took 0.000865 seconds\n",
      "2019-06-20 17:13:52,100 INFO TPE using 69/69 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:14:32,430 INFO tpe_transform took 0.000827 seconds\n",
      "2019-06-20 17:14:32,432 INFO TPE using 70/70 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:15:12,692 INFO tpe_transform took 0.001346 seconds\n",
      "2019-06-20 17:15:12,694 INFO TPE using 71/71 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:15:52,681 INFO tpe_transform took 0.001133 seconds\n",
      "2019-06-20 17:15:52,682 INFO TPE using 72/72 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:16:33,136 INFO tpe_transform took 0.001167 seconds\n",
      "2019-06-20 17:16:33,137 INFO TPE using 73/73 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:17:13,210 INFO tpe_transform took 0.000802 seconds\n",
      "2019-06-20 17:17:13,211 INFO TPE using 74/74 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:17:53,536 INFO tpe_transform took 0.001106 seconds\n",
      "2019-06-20 17:17:53,538 INFO TPE using 75/75 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:18:33,659 INFO tpe_transform took 0.001098 seconds\n",
      "2019-06-20 17:18:33,660 INFO TPE using 76/76 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:19:13,801 INFO tpe_transform took 0.000888 seconds\n",
      "2019-06-20 17:19:13,802 INFO TPE using 77/77 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:19:54,133 INFO tpe_transform took 0.000831 seconds\n",
      "2019-06-20 17:19:54,134 INFO TPE using 78/78 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:20:34,618 INFO tpe_transform took 0.000816 seconds\n",
      "2019-06-20 17:20:34,619 INFO TPE using 79/79 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:21:15,056 INFO tpe_transform took 0.000825 seconds\n",
      "2019-06-20 17:21:15,057 INFO TPE using 80/80 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:21:55,413 INFO tpe_transform took 0.000831 seconds\n",
      "2019-06-20 17:21:55,414 INFO TPE using 81/81 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:22:35,462 INFO tpe_transform took 0.000939 seconds\n",
      "2019-06-20 17:22:35,464 INFO TPE using 82/82 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:23:15,888 INFO tpe_transform took 0.000828 seconds\n",
      "2019-06-20 17:23:15,890 INFO TPE using 83/83 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:23:55,957 INFO tpe_transform took 0.000821 seconds\n",
      "2019-06-20 17:23:55,959 INFO TPE using 84/84 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:24:36,330 INFO tpe_transform took 0.000789 seconds\n",
      "2019-06-20 17:24:36,331 INFO TPE using 85/85 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:25:16,718 INFO tpe_transform took 0.000858 seconds\n",
      "2019-06-20 17:25:16,720 INFO TPE using 86/86 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:25:57,191 INFO tpe_transform took 0.000902 seconds\n",
      "2019-06-20 17:25:57,192 INFO TPE using 87/87 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:26:37,348 INFO tpe_transform took 0.000834 seconds\n",
      "2019-06-20 17:26:37,350 INFO TPE using 88/88 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:27:17,560 INFO tpe_transform took 0.000816 seconds\n",
      "2019-06-20 17:27:17,562 INFO TPE using 89/89 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.992  -- Validation score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:27:58,141 INFO tpe_transform took 0.000828 seconds\n",
      "2019-06-20 17:27:58,143 INFO TPE using 90/90 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:28:38,319 INFO tpe_transform took 0.000796 seconds\n",
      "2019-06-20 17:28:38,320 INFO TPE using 91/91 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:29:18,711 INFO tpe_transform took 0.000818 seconds\n",
      "2019-06-20 17:29:18,713 INFO TPE using 92/92 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:29:59,082 INFO tpe_transform took 0.001196 seconds\n",
      "2019-06-20 17:29:59,083 INFO TPE using 93/93 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:30:39,397 INFO tpe_transform took 0.000807 seconds\n",
      "2019-06-20 17:30:39,398 INFO TPE using 94/94 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:31:19,486 INFO tpe_transform took 0.000801 seconds\n",
      "2019-06-20 17:31:19,487 INFO TPE using 95/95 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:31:59,556 INFO tpe_transform took 0.001060 seconds\n",
      "2019-06-20 17:31:59,558 INFO TPE using 96/96 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:32:39,300 INFO tpe_transform took 0.000825 seconds\n",
      "2019-06-20 17:32:39,302 INFO TPE using 97/97 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:33:19,439 INFO tpe_transform took 0.000804 seconds\n",
      "2019-06-20 17:33:19,441 INFO TPE using 98/98 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000  -- Validation score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-20 17:33:59,676 INFO tpe_transform took 0.000821 seconds\n",
      "2019-06-20 17:33:59,678 INFO TPE using 99/99 trials with best loss 0.112403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.998  -- Validation score: 0.860\n",
      "Train score: 1.000  -- Validation score: 0.888\n",
      "{'alpha': 0.7929974893280227, 'cap': 0.03068184073438316, 'min_samples_leaf': 0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "space = {\n",
    "    #'criterion': hp.choice( 'criterion', ( 'gini', 'entropy' )),\n",
    "    #'bootstrap': hp.choice( 'bootstrap', ( True, False )),\n",
    "    #'class_weight': hp.choice( 'class_weight', ( 'balanced', 'balanced_subsample', None )),\n",
    "    #'max_depth': hp.choice('max_depth', np.arange( 2, 80, dtype=int)),\n",
    "    #'max_features': hp.choice( 'mf', ( 'sqrt', 'log2', None )),\n",
    "    #'min_samples_split': hp.choice('min_samples_split', np.arange( 2, 20, dtype=int)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange( 1, 3, dtype=int)),\n",
    "    'alpha': hp.uniform('alpha', 0.01, 0.8),\n",
    "    'cap': hp.uniform('cap', 0.01, 0.2)\n",
    "    #'n_estimators': hp.choice( 'n_estimators', [100,150, 200, 250, 300, 350,500]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# X_train, X_cv, y_train, y_cv = train_test_split(X_B,\n",
    "#                                                 y, \n",
    "#                                                 test_size=0.1, \n",
    "#                                                 random_state=random_state, \n",
    "#                                                 stratify=y)\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    clf = Liquid_Voter2(random_state=random_state, **space)\n",
    "    clf.fit(tr, y_train)\n",
    "    pred = clf.predict(tr_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(tr))\n",
    "    print(\"Train score: %0.3f  -- Validation score: %0.3f\"% (train_acc, acc))\n",
    "    to_return = {'loss':1-acc, 'train_loss':1-train_acc, 'status': STATUS_OK }\n",
    "    to_return.update(space)\n",
    "    return to_return\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch the trials results\n",
    "And keep a separate Dataframe for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "Index([u'alpha', u'cap', u'loss', u'min_samples_leaf', u'train_loss'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "tt = [t['result'] for t in trials.trials]\n",
    "dd = pd.DataFrame(tt)\n",
    "# categorical_feats = ['criterion', \n",
    "#                      'class_weight', \n",
    "#                      'max_features',\n",
    "#                      'bootstrap']\n",
    "# dd_cat = dd[categorical_feats+['loss']+['train_loss']]\n",
    "# for cat in categorical_feats:\n",
    "#     del dd[cat]\n",
    "del dd['status']\n",
    "print(dd.shape)\n",
    "print(dd.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot the table\n",
    "(this can be done more efficiently probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>cap</th>\n",
       "      <th>loss</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.180784</td>\n",
       "      <td>0.158915</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.180784</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289324</td>\n",
       "      <td>0.158601</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.289324</td>\n",
       "      <td>0.158601</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150716</td>\n",
       "      <td>0.164847</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.150716</td>\n",
       "      <td>0.164847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.124103</td>\n",
       "      <td>0.166192</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.124103</td>\n",
       "      <td>0.166192</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.073189</td>\n",
       "      <td>0.165355</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.073189</td>\n",
       "      <td>0.165355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.552070</td>\n",
       "      <td>0.107728</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.552070</td>\n",
       "      <td>0.107728</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.676491</td>\n",
       "      <td>0.124759</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.676491</td>\n",
       "      <td>0.124759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.746134</td>\n",
       "      <td>0.095601</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.746134</td>\n",
       "      <td>0.095601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.752158</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.752158</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.198583</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.198583</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.019734</td>\n",
       "      <td>0.127462</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.019734</td>\n",
       "      <td>0.127462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.355282</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.355282</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.616710</td>\n",
       "      <td>0.104644</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.616710</td>\n",
       "      <td>0.104644</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.548893</td>\n",
       "      <td>0.154616</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.548893</td>\n",
       "      <td>0.154616</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.199636</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.199636</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.565141</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.565141</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.047907</td>\n",
       "      <td>0.140717</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.047907</td>\n",
       "      <td>0.140717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.240269</td>\n",
       "      <td>0.144894</td>\n",
       "      <td>0.143411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.240269</td>\n",
       "      <td>0.144894</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.640247</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.640247</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.443611</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.443611</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.363817</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.363817</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.385501</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.385501</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.782512</td>\n",
       "      <td>0.100379</td>\n",
       "      <td>0.143411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.782512</td>\n",
       "      <td>0.100379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.709852</td>\n",
       "      <td>0.122044</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.709852</td>\n",
       "      <td>0.122044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.679155</td>\n",
       "      <td>0.072374</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.679155</td>\n",
       "      <td>0.072374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.789956</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.789956</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.540551</td>\n",
       "      <td>0.092066</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.540551</td>\n",
       "      <td>0.092066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.542738</td>\n",
       "      <td>0.110201</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.542738</td>\n",
       "      <td>0.110201</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.657390</td>\n",
       "      <td>0.033081</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.657390</td>\n",
       "      <td>0.033081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha       cap      loss  min_samples_leaf    set\n",
       "0    0.017807  0.180784  0.158915               2.0   Test\n",
       "1    0.017807  0.180784  0.006678               2.0  Train\n",
       "2    0.792997  0.030682  0.112403               1.0   Test\n",
       "3    0.792997  0.030682  0.000000               1.0  Train\n",
       "4    0.289324  0.158601  0.147287               2.0   Test\n",
       "5    0.289324  0.158601  0.005008               2.0  Train\n",
       "6    0.150716  0.164847  0.112403               1.0   Test\n",
       "7    0.150716  0.164847  0.000000               1.0  Train\n",
       "8    0.124103  0.166192  0.151163               2.0   Test\n",
       "9    0.124103  0.166192  0.006678               2.0  Train\n",
       "10   0.073189  0.165355  0.112403               1.0   Test\n",
       "11   0.073189  0.165355  0.000000               1.0  Train\n",
       "12   0.552070  0.107728  0.139535               2.0   Test\n",
       "13   0.552070  0.107728  0.001669               2.0  Train\n",
       "14   0.676491  0.124759  0.112403               1.0   Test\n",
       "15   0.676491  0.124759  0.000000               1.0  Train\n",
       "16   0.746134  0.095601  0.131783               2.0   Test\n",
       "17   0.746134  0.095601  0.000000               2.0  Train\n",
       "18   0.752158  0.138945  0.155039               2.0   Test\n",
       "19   0.752158  0.138945  0.000000               2.0  Train\n",
       "20   0.740980  0.198583  0.151163               2.0   Test\n",
       "21   0.740980  0.198583  0.005008               2.0  Train\n",
       "22   0.019734  0.127462  0.112403               1.0   Test\n",
       "23   0.019734  0.127462  0.000000               1.0  Train\n",
       "24   0.355282  0.039179  0.112403               1.0   Test\n",
       "25   0.355282  0.039179  0.000000               1.0  Train\n",
       "26   0.616710  0.104644  0.139535               2.0   Test\n",
       "27   0.616710  0.104644  0.001669               2.0  Train\n",
       "28   0.548893  0.154616  0.127907               2.0   Test\n",
       "29   0.548893  0.154616  0.003339               2.0  Train\n",
       "..        ...       ...       ...               ...    ...\n",
       "170  0.199636  0.163730  0.112403               1.0   Test\n",
       "171  0.199636  0.163730  0.000000               1.0  Train\n",
       "172  0.565141  0.127726  0.112403               1.0   Test\n",
       "173  0.565141  0.127726  0.000000               1.0  Train\n",
       "174  0.047907  0.140717  0.112403               1.0   Test\n",
       "175  0.047907  0.140717  0.000000               1.0  Train\n",
       "176  0.240269  0.144894  0.143411               2.0   Test\n",
       "177  0.240269  0.144894  0.008347               2.0  Train\n",
       "178  0.640247  0.118057  0.112403               1.0   Test\n",
       "179  0.640247  0.118057  0.000000               1.0  Train\n",
       "180  0.443611  0.088638  0.112403               1.0   Test\n",
       "181  0.443611  0.088638  0.000000               1.0  Train\n",
       "182  0.363817  0.060572  0.112403               1.0   Test\n",
       "183  0.363817  0.060572  0.000000               1.0  Train\n",
       "184  0.385501  0.064157  0.112403               1.0   Test\n",
       "185  0.385501  0.064157  0.000000               1.0  Train\n",
       "186  0.782512  0.100379  0.143411               2.0   Test\n",
       "187  0.782512  0.100379  0.000000               2.0  Train\n",
       "188  0.709852  0.122044  0.112403               1.0   Test\n",
       "189  0.709852  0.122044  0.000000               1.0  Train\n",
       "190  0.679155  0.072374  0.112403               1.0   Test\n",
       "191  0.679155  0.072374  0.000000               1.0  Train\n",
       "192  0.789956  0.082051  0.112403               1.0   Test\n",
       "193  0.789956  0.082051  0.000000               1.0  Train\n",
       "194  0.540551  0.092066  0.112403               1.0   Test\n",
       "195  0.540551  0.092066  0.000000               1.0  Train\n",
       "196  0.542738  0.110201  0.139535               2.0   Test\n",
       "197  0.542738  0.110201  0.001669               2.0  Train\n",
       "198  0.657390  0.033081  0.112403               1.0   Test\n",
       "199  0.657390  0.033081  0.000000               1.0  Train\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = []\n",
    "for i, row in dd.iterrows():\n",
    "    cur = {}\n",
    "    cur['loss'] = row['loss']\n",
    "    train_loss = row['train_loss']\n",
    "    del row['loss']\n",
    "    del row['train_loss']\n",
    "    cur['set'] = \"Test\"\n",
    "    cur.update(row.to_dict())\n",
    "    tr.append(cur)\n",
    "    cur = {}\n",
    "    cur['loss'] = train_loss\n",
    "    cur['set'] = \"Train\"\n",
    "    cur.update(row.to_dict())\n",
    "    tr.append(cur)\n",
    "dd2 = pd.DataFrame(tr)\n",
    "dd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same for the categorical Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dd_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7ee156885dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdd_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dd_cat' is not defined"
     ]
    }
   ],
   "source": [
    "tr = []\n",
    "for i, row in dd_cat.iterrows():\n",
    "    cur = {}\n",
    "    cur['loss'] = row['loss']\n",
    "    train_loss = row['train_loss']\n",
    "    del row['loss']\n",
    "    del row['train_loss']\n",
    "    cur['set'] = \"Test\"\n",
    "    cur.update(row.to_dict())\n",
    "    tr.append(cur)\n",
    "    cur = {}\n",
    "    cur['loss'] = train_loss\n",
    "    cur['set'] = \"Train\"\n",
    "    cur.update(row.to_dict())\n",
    "    tr.append(cur)\n",
    "dd2_cat = pd.DataFrame(tr)\n",
    "dd2_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1141.48x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "dd2_melted = dd2.melt(['loss', 'set'])\n",
    "g = sns.lmplot(x=\"value\", y=\"loss\", col=\"variable\", hue='set', data=dd2_melted,sharex=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.01, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results\n",
    "(Categorical Vars into boxplot)\n",
    "This needs some fixing for the empty labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2_cat_melted = dd2_cat.melt(['loss', 'set'])\n",
    "g = sns.catplot(x=\"value\", y=\"loss\", col='variable', hue='set', \n",
    "                data=dd2_cat_melted, sharex=False,\n",
    "                kind='box')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
