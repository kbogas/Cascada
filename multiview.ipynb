{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 178 x 13\n",
      "('1st row', array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
      "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
      "       1.065e+03]))\n",
      "Results for: Logistic Regression\n",
      "0.9722222222222222\n",
      "[[11  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n",
      "Results for: Random Forest\n",
      "0.9166666666666666\n",
      "[[12  0  0]\n",
      " [ 1 13  0]\n",
      " [ 0  2  8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        12\n",
      "          1       0.87      0.93      0.90        14\n",
      "          2       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.92      0.92      0.92        36\n",
      "\n",
      "Results for: RBF kernel SVM\n",
      "0.4444444444444444\n",
      "[[ 1 11  0]\n",
      " [ 0 14  0]\n",
      " [ 0  9  1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        12\n",
      "          1       0.41      1.00      0.58        14\n",
      "          2       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.77      0.44      0.33        36\n",
      "\n",
      "Results for: Ensemble\n",
      "0.9166666666666666\n",
      "[[11  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        12\n",
      "          1       0.82      1.00      0.90        14\n",
      "          2       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.93      0.92      0.92        36\n",
      "\n",
      "Results for: Stacking\n",
      "1.0\n",
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        36\n",
      "\n",
      "Will create 60 trees!\n",
      "[*****************48%                  ]  29 of 60 complete Results for: MULTIVIEWER\n",
      "(36, 13)\n",
      "36\n",
      "0.9166666666666666\n",
      "[[12  0  0]\n",
      " [ 3 11  0]\n",
      " [ 0  0 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        12\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.93      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from brew.base import Ensemble, EnsembleClassifier\n",
    "from brew.stacking.stacker import EnsembleStack, EnsembleStackClassifier\n",
    "from brew.combination.combiner import Combiner\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from mlxtend.data import wine_data, iris_data\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from progress.bar import Bar\n",
    "\n",
    "import sys, time\n",
    "try:\n",
    "    from IPython.core.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, iterations):\n",
    "        self.iterations = iterations\n",
    "        self.prog_bar = '[]'\n",
    "        self.fill_char = '*'\n",
    "        self.width = 40\n",
    "        self.__update_amount(0)\n",
    "        if have_ipython:\n",
    "            self.animate = self.animate_ipython\n",
    "        else:\n",
    "            self.animate = self.animate_noipython\n",
    "\n",
    "    def animate_ipython(self, iter):\n",
    "        try:\n",
    "            pass\n",
    "            #clear_output()\n",
    "        except Exception:\n",
    "            # terminal IPython has no clear_output\n",
    "            pass\n",
    "        print '\\r', self,\n",
    "        #sys.stdout.flush()\n",
    "        self.update_iteration(iter + 1)\n",
    "\n",
    "    def update_iteration(self, elapsed_iter):\n",
    "        self.__update_amount((elapsed_iter / float(self.iterations)) * 100.0)\n",
    "        self.prog_bar += '  %d of %s complete' % (elapsed_iter, self.iterations)\n",
    "\n",
    "    def __update_amount(self, new_amount):\n",
    "        percent_done = int(round((new_amount / 100.0) * 100.0))\n",
    "        all_full = self.width - 2\n",
    "        num_hashes = int(round((percent_done / 100.0) * all_full))\n",
    "        self.prog_bar = '[' + self.fill_char * num_hashes + ' ' * (all_full - num_hashes) + ']'\n",
    "        pct_place = (len(self.prog_bar) / 2) - len(str(percent_done))\n",
    "        pct_string = '%d%%' % percent_done\n",
    "        self.prog_bar = self.prog_bar[0:pct_place] + \\\n",
    "            (pct_string + self.prog_bar[pct_place + len(pct_string):])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.prog_bar)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Multiviewer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, max_level=3, num_at_each_level=4, base_estimator=ExtraTreesClassifier(n_estimators=50)):\n",
    "        self.max_level = max_level\n",
    "        self.base_estimator = base_estimator\n",
    "        self.num_at_each_level = num_at_each_level\n",
    "        self.estimators = []\n",
    "        self.estim_features = []\n",
    "        self.classes_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.max_level > X.shape[1]:\n",
    "            print \"Max level of feature combinations can't be bigger than num of features\"\n",
    "            print \"%d > %d\" % (self.max_level, X.shape[1])\n",
    "            raise ValueError\n",
    "        if not(isinstance(self.num_at_each_level, list)):\n",
    "            self.num_at_each_level = [self.num_at_each_level for i in xrange(1, self.max_level)]\n",
    "            self.num_at_each_level = [X.shape[1]] + self.num_at_each_level \n",
    "        #print self.num_at_each_level\n",
    "        self.classes_ = list(set(y))\n",
    "        rang = np.arange(X.shape[1])\n",
    "        total = 0\n",
    "        for i in xrange(1, self.max_level+1):\n",
    "            total += i* self.num_at_each_level[i-1]\n",
    "        print \"Will create %d trees!\" % total\n",
    "        cc = 0\n",
    "        bar =ProgressBar(total)\n",
    "        for level in xrange(self.max_level):\n",
    "            #print [comb for comb in combinations(rang, level+1)]\n",
    "            wanted_feature_sets = get_cols(rang, level+1, self.num_at_each_level[level] )\n",
    "            for wanted_features in wanted_feature_sets:\n",
    "                c = sklearn.clone(self.base_estimator)\n",
    "                c.fit(X[:, wanted_features], y)\n",
    "                self.estimators.append(c)\n",
    "                #print self.estimators[-1].n_features_\n",
    "                self.estim_features.append(wanted_features)\n",
    "                bar.animate(cc)\n",
    "                cc += 1\n",
    "        #bar.finish()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not(isinstance(X, np.ndarray)):\n",
    "            X = np.array(X)\n",
    "        print X.shape\n",
    "        print X.shape[0]\n",
    "        predictions = np.empty((X.shape[0], len(self.estimators)))\n",
    "        for i, est in enumerate(self.estimators):\n",
    "#             print est.n_features_\n",
    "#             print i, self.estim_features[i]\n",
    "#             print X.shape\n",
    "#             print X[:, self.estim_features[i]].shape\n",
    "            predictions[:, i] = est.predict(X[:, self.estim_features[i]])\n",
    "        final_pred = []\n",
    "        #print predictions\n",
    "        for sample in xrange(X.shape[0]):\n",
    "            votes = []\n",
    "            for i, mod_vote in enumerate(predictions[sample,:]):\n",
    "                votes.extend([predictions[sample, i] for j in xrange(1)])\n",
    "            final_pred.append(most_common(votes))\n",
    "        return np.array(final_pred).reshape(-1,)\n",
    "    \n",
    "def get_cols(iterable, level_, total_times_):\n",
    "    wanted = [random.sample(iterable, k=level_) for time in xrange(total_times_)]\n",
    "    return wanted\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "\n",
    "\n",
    "# Loading some example data\n",
    "X, y = wine_data()\n",
    "#X, y = iris_data()\n",
    "#X = X[:,[0, 2]]\n",
    "\n",
    "\n",
    "print('Dimensions: %s x %s' % (X.shape[0], X.shape[1]))\n",
    "print('1st row', X[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initializing Classifiersa\n",
    "clf1 = LogisticRegression(random_state=0)\n",
    "clf2 = RandomForestClassifier(random_state=0)\n",
    "clf3 = SVC(random_state=0, probability=True)\n",
    "mu = Multiviewer(max_level=3, num_at_each_level=[10, 10, 10])\n",
    "# Creating Ensemble\n",
    "ensemble = Ensemble([clf1, clf2, clf3])\n",
    "eclf = EnsembleClassifier(ensemble=ensemble, combiner=Combiner('mean'))\n",
    "# Creating Stacking\n",
    "layer_1 = Ensemble([clf1, clf2, clf3])\n",
    "layer_2 = Ensemble([sklearn.clone(clf1)])\n",
    "\n",
    "stack = EnsembleStack(cv=3)\n",
    "\n",
    "stack.add_layer(layer_1)\n",
    "stack.add_layer(layer_2)\n",
    "\n",
    "sclf = EnsembleStackClassifier(stack)\n",
    "\n",
    "clf_list = [clf1, clf2, clf3, eclf, sclf, mu]\n",
    "lbl_list = ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble', 'Stacking', 'MULTIVIEWER']\n",
    "\n",
    "\n",
    "\n",
    "# WARNING, WARNING, WARNING\n",
    "# brew requires classes from 0 to N, no skipping allowed\n",
    "d = {yi : i for i, yi in enumerate(set(y))}\n",
    "y = np.array([d[yi] for yi in y])\n",
    "\n",
    "# Plotting Decision Regions\n",
    "#gs = gridspec.GridSpec(2, 3)\n",
    "#fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "itt = itertools.product([0, 1, 2], repeat=2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y, random_state=100)\n",
    "\n",
    "for clf, lab, grd in zip(clf_list, lbl_list, itt):\n",
    "    clf.fit(X_train, y_train)\n",
    "#    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "#    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "#    plt.title(lab)\n",
    "    print \"Results for: %s\" % lab\n",
    "    pred = clf.predict(X_cv)\n",
    "    print accuracy_score(y_cv, pred, normalize=True)\n",
    "    print confusion_matrix(y_cv, pred, labels=list(set(y)))\n",
    "    print classification_report(y_cv, pred, labels=list(set(y)))\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "clf1.predict(X_cv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "class Multiviewer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, max_level=3, num_at_each_level=4, base_estimator=ExtraTreesClassifier(n_estimators=50)):\n",
    "        self.max_level = max_level\n",
    "        self.base_estimator = base_estimator\n",
    "        self.num_at_each_level = num_at_each_level\n",
    "        self.estimators = []\n",
    "        self.estim_features = []\n",
    "        self.classes_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.max_level > X.shape[1]:\n",
    "            print \"Max level of feature combinations can't be bigger than num of features\"\n",
    "            print \"%d > %d\" % (self.max_level, X.shape[1])\n",
    "            raise ValueError\n",
    "        if not(isinstance(self.num_at_each_level, list)):\n",
    "            self.num_at_each_level = [self.num_at_each_level for i in xrange(1, self.max_level)]\n",
    "            self.num_at_each_level = [X.shape[1]] + self.num_at_each_level \n",
    "        #print self.num_at_each_level\n",
    "        self.classes_ = list(set(y))\n",
    "        rang = np.arange(X.shape[1])\n",
    "        total = 0\n",
    "        for i in xrange(1, self.max_level+1):\n",
    "            total += i* self.num_at_each_level[i-1]\n",
    "        print \"Will create %d trees!\" % total\n",
    "        cc = 0\n",
    "        bar =ProgressBar(total)\n",
    "        for level in xrange(self.max_level):\n",
    "            #print [comb for comb in combinations(rang, level+1)]\n",
    "            wanted_feature_sets = get_cols(rang, level+1, self.num_at_each_level[level])\n",
    "            print wanted_feature_sets\n",
    "            for wanted_features in wanted_feature_sets:\n",
    "                c = sklearn.clone(self.base_estimator)\n",
    "                c.fit(X[:, wanted_features], y)\n",
    "                self.estimators.append(c)\n",
    "                #print self.estimators[-1].n_features_\n",
    "                self.estim_features.append(wanted_features)\n",
    "                bar.animate(cc)\n",
    "                cc += 1\n",
    "        #bar.finish()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not(isinstance(X, np.ndarray)):\n",
    "            X = np.array(X)\n",
    "        print X.shape\n",
    "        print X.shape[0]\n",
    "        predictions = np.empty((X.shape[0], len(self.estimators)))\n",
    "        for i, est in enumerate(self.estimators):\n",
    "#             print est.n_features_\n",
    "#             print i, self.estim_features[i]\n",
    "#             print X.shape\n",
    "#             print X[:, self.estim_features[i]].shape\n",
    "            predictions[:, i] = est.predict(X[:, self.estim_features[i]])\n",
    "        final_pred = []\n",
    "        #print predictions\n",
    "        for sample in xrange(X.shape[0]):\n",
    "            votes = []\n",
    "            for i, mod_vote in enumerate(predictions[sample,:]):\n",
    "                votes.extend([predictions[sample, i] for j in xrange(1)])\n",
    "            final_pred.append(most_common(votes))\n",
    "        return np.array(final_pred).reshape(-1,)\n",
    "    \n",
    "def get_cols(iterable, level_, total_times_):\n",
    "    wanted = [random.sample(iterable, k=level_) for time in xrange(total_times_)]\n",
    "    return wanted\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Will create 49 trees!\n",
      "[[1], [2], [2], [1], [12], [11], [6], [9], [9], [6], [5], [8], [7]]\n",
      "[*********        24%                  ]  12 of 49 complete [[3, 4], [8, 7], [2, 7], [11, 10]]\n",
      "[*************    33%                  ]  16 of 49 complete [[8, 0, 4], [1, 0, 2], [5, 9, 6], [3, 8, 5]]\n",
      "[**************** 41%                  ]  20 of 49 complete [[6, 3, 4, 11], [9, 5, 4, 10], [6, 8, 7, 11], [5, 9, 10, 11]]\n",
      "[*****************49%                  ]  24 of 49 complete (36, 13)\n",
      "36\n",
      "1.0\n",
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X.shape[1]\n",
    "mu = Multiviewer(max_level=4)\n",
    "mu.fit(X,y)\n",
    "pred = mu.predict(X_cv)\n",
    "print accuracy_score(y_cv, pred, normalize=True)\n",
    "print confusion_matrix(y_cv, pred, labels=list(set(y)))\n",
    "print classification_report(y_cv, pred, labels=list(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 13)\n",
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 1., 0., 2., 0., 2., 1., 2., 2., 0., 2., 2.,\n",
       "       1., 2., 0., 0., 1., 1., 0., 0., 1., 1., 2., 1., 1., 0., 2., 0., 1.,\n",
       "       1., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rang = np.arange(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(10)\n",
    "ss = random.sample([comb for comb in combinations(rang, 2)],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7,),\n",
       " (5,),\n",
       " (6,),\n",
       " (2,),\n",
       " (12,),\n",
       " (10,),\n",
       " (4,),\n",
       " (0,),\n",
       " (9,),\n",
       " (1,),\n",
       " (11,),\n",
       " (3,),\n",
       " (8,)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, ss[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
